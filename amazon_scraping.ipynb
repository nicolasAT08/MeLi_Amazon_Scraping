{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install requests\n",
    "# ! pip install beautifulsoup4\n",
    "# ! pip install matplotlib\n",
    "# ! pip install ipykernel\n",
    "# ! pip install requests-html\n",
    "# ! pip install selenium\n",
    "# ! pip install unidecode\n",
    "# ! pip install spacy\n",
    "# ! pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_amazon\n",
    "from importlib import reload\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from IPython.display import display\n",
    "pd.options.display.max_colwidth = 170\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = r\"\".replace(\"\\\\\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.cli.download(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# About 50 mins - 7 pag\n",
    "reload(utils_amazon)\n",
    "df = utils_amazon.load_html_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for specif word(s) in comments / Filter\n",
    "\n",
    "for idx in range(len(df)-1):\n",
    "    for comm in df.loc[idx,'Global Comments']:\n",
    "        if re.search(r'calidad', comm, flags=re.IGNORECASE):\n",
    "            display(df.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for specif word(s) in products / Filter\n",
    "\n",
    "# brand_producs = []\n",
    "# for i in df[df['Stars']==5]['Product']:\n",
    "#     if (re.search(r'', i, flags=re.IGNORECASE)) or (re.search(r'', i, flags=re.IGNORECASE)) or (re.search(r'', i, flags=re.IGNORECASE)):\n",
    "#     # if (re.search(r'', i, flags=re.IGNORECASE)) and (re.search(r'bamb.', i, flags=re.IGNORECASE) or re.search(r'nutre y crece', i, flags=re.IGNORECASE)): # or (re.search(r'[^bamboo].', i, flags=re.IGNORECASE))\n",
    "#         brand_producs.append(i)\n",
    "\n",
    "\n",
    "# df_filtered = df[df.Product.isin(brand_producs)].reset_index(drop=True)\n",
    "# df_filtered = df_filtered.drop_duplicates(subset=['Product', 'Price', 'Stars', 'Global Ratings'], keep='first',ignore_index=True)\n",
    "\n",
    "# print(df_filtered.shape)\n",
    "# df_filtered.head()\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Look for specif word(s) in products / Filter\n",
    "\n",
    "brand_producs = []\n",
    "for i in df['Product']:\n",
    "    if ((re.search(r'', i, flags=re.IGNORECASE)) or (re.search(r'', i, flags=re.IGNORECASE)) or (re.search(r'', i, flags=re.IGNORECASE))) and \\\n",
    "        ((re.search(r'colágeno', i, flags=re.IGNORECASE)) or (re.search(r'menta', i, flags=re.IGNORECASE))):\n",
    "        brand_producs.append(i)\n",
    "\n",
    "\n",
    "df_filtered = df[df.Product.isin(brand_producs)].reset_index(drop=True)\n",
    "df_filtered.drop_duplicates(subset=['Product', 'Price', 'Stars', 'Global Ratings'], keep='first',ignore_index=True, inplace=True)\n",
    "\n",
    "print(df_filtered.shape)\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a product in browser\n",
    "utils_amazon.open_link(df,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a filtered DataFrame\n",
    "df_filtered.to_excel(os.path.join(parent_path,\"_{}_{}_{}.xlsx\".format(datetime.today().year,datetime.today().month,datetime.today().day)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the DataFrame and copy and paste the product name or DataFrame idx you want to see in browser\n",
    "reload(utils_amazon)\n",
    "utils_amazon.open_link(df,'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from unidecode import unidecode\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.cli.download(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "pat = re.compile(r\"[^a-z ]\")\n",
    "spaces = re.compile(r\"\\s{2,}\")\n",
    "\n",
    "def preprocess(text, min_len=1, max_len=1000):\n",
    "    # spacy Doc creation\n",
    "    doc = nlp(text)\n",
    "    # Remove stopwords\n",
    "    filtered_tokens = filter(\n",
    "            lambda token: not token.is_stop,\n",
    "            doc\n",
    "            )\n",
    "    # Filter words by length and remove stop words\n",
    "    filtered_tokens2 = filter(\n",
    "            lambda token: len(token) >= min_len and len(token) <= max_len and not token.is_stop,\n",
    "            filtered_tokens\n",
    "        )\n",
    "    # Lemmatization\n",
    "    lemmas = map(\n",
    "            lambda token: token.lemma_,\n",
    "            filtered_tokens2\n",
    "            )\n",
    "    lemma_text = \" \".join(lemmas)\n",
    "    # Normalize text\n",
    "    norm_text = unidecode(lemma_text)\n",
    "    # Remove accents\n",
    "    lower_text = norm_text.lower()\n",
    "    # Remove special characters\n",
    "    clean_text = re.sub(pat, \"\", lower_text)\n",
    "    # Remomove duplicate spaces (if exist)\n",
    "    spaces_text = re.sub(spaces, \" \", clean_text)\n",
    "    return spaces_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments = []\n",
    "\n",
    "for comm in df_filtered['Global Comments']:\n",
    "    all_comments.extend(comm)\n",
    "\n",
    "print(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_comments = list(map(preprocess,all_comments))\n",
    "print(prep_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = (\n",
    "    CountVectorizer(max_features=1000, max_df=0.7)\n",
    "    .fit(prep_comments)\n",
    "    )\n",
    "\n",
    "X = vect.transform(prep_comments)\n",
    "vocab = vect.get_feature_names_out()\n",
    "\n",
    "counts = np.array(X.sum(axis=0)).flatten()\n",
    "counts_dict = {word: count for word, count in zip(vocab, counts)}\n",
    "\n",
    "mask = np.array(Image.open(r\"\\cloud.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color='white',\n",
    "        width=3000,\n",
    "        height=2000,\n",
    "        collocations=False,\n",
    "        mask=mask,\n",
    "        colormap = 'Dark2',\n",
    "        max_words=40\n",
    ").generate_from_frequencies(counts_dict)\n",
    "\n",
    "plt.figure(figsize=[7,7])\n",
    "plt.imshow(wc,interpolation=\"bilinear\")\n",
    "plt.axis(\"off\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competition: competition brands scraping and then concatenate DataFrames.\n",
    "\n",
    "comp = [\"L'oréal\", \"OGX\", \"Tío Nacho\"]\n",
    "files = os.listdir(parent_path)[1::]\n",
    "df_competition = pd.DataFrame()\n",
    "\n",
    "# for c in comp:\n",
    "for f, c in zip(files, comp):\n",
    "    df_temp = pd.read_excel(os.path.join(parent_path,f))\n",
    "    df_temp[\"Brand\"] = c\n",
    "    df_temp.drop_duplicates(subset=['Product', 'Price', 'Stars', 'Ratings'], keep='first',ignore_index=True, inplace=True)\n",
    "    df_competition = pd.concat([df_competition, df_temp], axis=0).reset_index(drop=True)\n",
    "    # print(df_temp.shape)\n",
    "    del df_temp\n",
    "    \n",
    "df_competition = df_competition[['Brand', 'Product', 'Price', 'Stars', 'Ratings', 'Ratings MX', 'Comments Global', 'Link']]\n",
    "print(df_competition.shape)\n",
    "display(df_competition.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a DataFrame\n",
    "df_competition.to_excel(os.path.join(parent_path,\"competition_{}_{}_{}.xlsx\".format(datetime.today().year,datetime.today().month,datetime.today().day)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_comments = 0\n",
    "for i in df_competition.loc[(df_competition[\"Brand\"] == \"Tío Nacho\")].drop_duplicates(subset=['Product', 'Price', 'Stars', 'Ratings'], keep='first',ignore_index=False, inplace=False).sort_values(by='Stars', ascending=False)['Comments Global']:\n",
    "    total_comments += i.__len__()\n",
    "print(df_competition.loc[(df_competition[\"Brand\"] == \"Tío Nacho\")].drop_duplicates(subset=['Product', 'Price', 'Stars', 'Ratings'], keep='first',ignore_index=False, inplace=False).sort_values(by='Stars', ascending=False)['Ratings'].sum())\n",
    "print(total_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_competition.loc[(df_competition[\"Brand\"] == \"Tío Nacho\")].drop_duplicates(subset=['Product', 'Price', 'Stars', 'Ratings'], keep='first',ignore_index=False, inplace=False).sort_values(by='Stars', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_competition.groupby(\"Brand\")[\"Product\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a product in browser\n",
    "utils_amazon.open_link(df_competition,32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(os.path.join(parent_path,\"\".replace(\"\\\\\", \"/\")))\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils_amazon)\n",
    "df_25 = utils_amazon.quartile_prices(df)[0]\n",
    "df_25_50 = utils_amazon.quartile_prices(df)[1]\n",
    "df_50_75 = utils_amazon.quartile_prices(df)[2]\n",
    "df_75 = utils_amazon.quartile_prices(df)[3]\n",
    "quartiles = utils_amazon.quartile_prices(df)[4]\n",
    "quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Products above quartile 75\n",
    "print('Prime products [above quartile 75] -> {} products ({}%) '.format(df_75.Product.to_list().__len__(), round((df_75.Product.to_list().__len__() / df.__len__()) * 100, 2)))\n",
    "print('Premium products [between quartiles 50 & 75] -> {} products ({}%) '.format(df_50_75.Product.to_list().__len__(), round((df_50_75.Product.to_list().__len__() / df.__len__()) * 100, 2)))\n",
    "print('Mid products [between quartiles 25 & 50] -> {} products ({}%) '.format(df_25_50.Product.to_list().__len__(), round((df_25_50.Product.to_list().__len__() / df.__len__()) * 100, 2)))\n",
    "print('Low products [below quartile 25 ] -> {} products ({}%) '.format(df_25.Product.to_list().__len__(), round((df_25.Product.to_list().__len__() / df.__len__()) * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quartile (75>) - Products: {}'.format(df_75.__len__()))\n",
    "display(df_75.head())\n",
    "print('Quartile (50-75] - Products: {}'.format(df_50_75.__len__()))\n",
    "display(df_50_75.head())\n",
    "print('Quartile (25-50] - Products: {}'.format(df_25_50.__len__()))\n",
    "display(df_25_50.head())\n",
    "print('Quartile (<25] - Products: {}'.format(df_25.__len__()))\n",
    "display(df_25.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.Price <= 360].shape[0])\n",
    "px.box(df,'Price', title=f'Price distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Price >= 176].shape[0] / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(px.histogram(df, x='Price', title=f'Price distribution'))\n",
    "display(px.histogram(df_75, x='Price', title=f'Price distribution - Prime Products', nbins=10, text_auto=True))\n",
    "display(df_75.describe().round(2))\n",
    "display(px.histogram(df_50_75, x='Price', title=f'Price distribution - Premium Products', nbins=15, text_auto=True))\n",
    "display(df_50_75.describe().round(2))\n",
    "display(px.histogram(df_25_50, x='Price', title=f'Price distribution - Mid Products', nbins=15, text_auto=True))\n",
    "display(df_25_50.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_75.Product.unique().tolist()[:10])\n",
    "print()\n",
    "display(df_50_75.Product.unique().tolist()[:10])\n",
    "print()\n",
    "display(df_25_50.Product.unique().tolist()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prime Products\n",
    "display(df_75.Product.value_counts().to_frame().reset_index().rename(columns={'index':'Product','Product':'Results'}).head(10))\n",
    "for i in df_75.Product.value_counts().to_frame().reset_index().rename(columns={'index':'Product','Product':'Results'}).head(10).Product.tolist():\n",
    "    print(i)\n",
    "\n",
    "#Premium Products\n",
    "display(df_50_75.Product.value_counts().to_frame().reset_index().rename(columns={'index':'Product','Product':'Results'}).head(10))\n",
    "for i in df_50_75.Product.value_counts().to_frame().reset_index().rename(columns={'index':'Product','Product':'Results'}).head(10).Product.tolist():\n",
    "    print(i)\n",
    "\n",
    "#Mid Products\n",
    "display(df_25_50.Product.value_counts().to_frame().reset_index().rename(columns={'index':'Product','Product':'Results'}).head(10))\n",
    "for i in df_25_50.Product.value_counts().to_frame().reset_index().rename(columns={'index':'Product','Product':'Results'}).head(10).Product.tolist():\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brands distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for specif word(s)\n",
    "\n",
    "brand_producs = []\n",
    "for i in df['Product']:\n",
    "    if (re.search(r'colágeno.', i, flags=re.IGNORECASE) or re.search(r'nutre y revitaliza', i, flags=re.IGNORECASE) or re.search(r'nutre & revitaliza', i, flags=re.IGNORECASE)) and (re.search(r'pantene', i, flags=re.IGNORECASE)) and not (re.search(r'bamb', i, flags=re.IGNORECASE) or re.search(r'nutrient blend.', i, flags=re.IGNORECASE)) : # or (re.search(r'[^bamboo].', i, flags=re.IGNORECASE))\n",
    "        brand_producs.append(i)\n",
    "\n",
    "\n",
    "brand_df = df[df.Product.isin(brand_producs)].reset_index(drop=True)\n",
    "\n",
    "#brand_df = brand_df.drop([4,5,7,8,9,10,11,13]).reset_index(drop=True)\n",
    "\n",
    "brand_df.to_excel(os.path.join(parent_path,\"_{}_{}_{}.xlsx\".format(datetime.today().year,datetime.today().month,datetime.today().day)), index=False)\n",
    "print(brand_df.shape)\n",
    "brand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_amazon.open_link(brand_df,8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af37c3268cca26f2bfaf01d13423ff37a9d7634ed8fa0992ffd17d42608d9c97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
